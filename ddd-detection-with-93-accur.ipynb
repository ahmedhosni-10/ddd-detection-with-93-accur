{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1520586,"sourceType":"datasetVersion","datasetId":896350}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# libraries","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\n\n # For interacting with the operating system\nimport os \n\n# For numerical operations on arrays\nimport numpy as np  \n\n# For image processing\nimport cv2  \n\n # For generating random numbers\nimport random \n\n# For plotting and visualization\nimport matplotlib.pyplot as plt  \n\n\n# Import specific functionalities from TensorFlow and Scikit-learn\n\n # For deep learning\nimport tensorflow as tf \n\n# For data augmentation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \n\n# For converting labels to one-hot encoding\nfrom tensorflow.keras.utils import to_categorical  \n\n# For building and loading models\nfrom tensorflow.keras.models import Sequential, load_model  \n\n# For splitting data into training and validation sets\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# For building layers of the neural network\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-27T10:12:19.207237Z","iopub.execute_input":"2024-12-27T10:12:19.207553Z","iopub.status.idle":"2024-12-27T10:12:31.275944Z","shell.execute_reply.started":"2024-12-27T10:12:19.207524Z","shell.execute_reply":"2024-12-27T10:12:31.274977Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"# Initialize lists to hold images and their corresponding labels\nimages = []\nlabels = []\n\n# Loop through each label directory\nfor index, label in enumerate(['Closed', 'Open', 'no_yawn', 'yawn']):  # Assign numeric labels: 0, 1, 2, 3\n    \n    train_path = '/kaggle/input/drowsiness-dataset/train'\n    \n    images_folder_path = os.path.join(train_path, label)  # Construct the path to the image folder for the current label\n\n    # Loop through all images in the current label directory\n    for image_number in os.listdir(images_folder_path):\n        # Construct the full path to the image\n        image_path = os.path.join(images_folder_path, image_number)\n        \n        # Read the image using matplotlib\n        image = plt.imread(image_path)\n        \n        # Resize the image to (150, 150) using OpenCV\n        resized_image = cv2.resize(image, (150, 150))\n        \n        # Convert the image to grayscale\n        image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY) \n        \n        # Append the processed image and its label to the respective lists\n        images.append(image)\n        labels.append(index) # numeric labels\n\n# Convert the lists of images and labels to NumPy arrays for efficient numerical operations\nimages = np.array(images)\nlabels = np.array(labels)\n\nprint(f\"Images shape: {images.shape}\")\nprint(f\"Labels shape: {labels.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T10:12:31.277459Z","iopub.execute_input":"2024-12-27T10:12:31.277938Z","iopub.status.idle":"2024-12-27T10:13:00.091497Z","shell.execute_reply.started":"2024-12-27T10:12:31.277907Z","shell.execute_reply":"2024-12-27T10:13:00.090570Z"}},"outputs":[{"name":"stdout","text":"Images shape: (2900, 150, 150)\nLabels shape: (2900,)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Split Data","metadata":{}},{"cell_type":"code","source":"# Ensure the images have an additional channel dimension for compatibility with CNNs\nimages = np.expand_dims(images, axis=-1)\n\n# Split the data into training and temporary sets (60% training, 40% temporary)\nx_train, x_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.4, \n                                                    shuffle=True, random_state=42)\n\n# Split the temporary set into validation and test sets (20% each from the original data)\nx_test, x_val, y_test, y_val = train_test_split(x_temp, y_temp, test_size=0.5, \n                                                shuffle=True, random_state=42)\n\n# Convert the labels to one-hot encoded format for the neural network\ny_train = to_categorical(y_train, num_classes=4)\ny_val = to_categorical(y_val, num_classes=4)\ny_test = to_categorical(y_test, num_classes=4)\n\n# Print the shapes of the training, validation, and test sets\nprint(f'Train set: {x_train.shape}, {y_train.shape}') \nprint(f'Validation set: {x_val.shape}, {y_val.shape}')\nprint(f'Test set: {x_test.shape}, {y_test.shape}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:21:11.413862Z","iopub.status.idle":"2024-12-26T21:21:11.414366Z","shell.execute_reply.started":"2024-12-26T21:21:11.414042Z","shell.execute_reply":"2024-12-26T21:21:11.414067Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Import the necessary library for data augmentation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define custom contrast adjustment function\ndef random_contrast(image, lower=0.9, upper=1.1):\n    return tf.image.random_contrast(image, lower=lower, upper=upper)\n\n# Define custom preprocessing function\ndef custom_preprocess(image):\n    image = random_contrast(image)\n    return image\n\n# Define ImageDataGenerators for data augmentation and normalization\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    brightness_range=[0.9, 1.1],\n    preprocessing_function=custom_preprocess\n)\n\nval_test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values for validation and test data to the range [0, 1]\n\n# Create data generators for training, validation, and test sets\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size=32)  # Generate batches of tensor image data for training\nval_generator = val_test_datagen.flow(x_val, y_val, batch_size=32)  # Generate batches of tensor image data for validation\ntest_generator = val_test_datagen.flow(x_test, y_test, batch_size=32)  # Generate batches of tensor image data for testing\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:21:11.415946Z","iopub.status.idle":"2024-12-26T21:21:11.416284Z","shell.execute_reply.started":"2024-12-26T21:21:11.416110Z","shell.execute_reply":"2024-12-26T21:21:11.416126Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# Determine the input shape for the CNN based on the shape of the images\ninput_shape = images.shape[1:] \nprint(\"Input shape:\", input_shape)\n\n# Define a function to create the CNN model\ndef create_model():\n    model = Sequential([\n        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),  # First convolutional layer\n        MaxPooling2D(pool_size=(2, 2)),  # First max pooling layer\n        Conv2D(64, (3, 3), activation='relu'),  # Second convolutional layer\n        MaxPooling2D(pool_size=(2, 2)),  # Second max pooling layer\n        Conv2D(128, (3, 3), activation='relu'),  # Third convolutional layer\n        MaxPooling2D(pool_size=(2, 2)),  # Third max pooling layer\n        Flatten(),  # Flatten the feature map to a 1D vector\n        Dense(256, activation='relu'),  # Fully connected layer with 256 units\n        Dropout(0.5),  # Dropout layer to prevent overfitting\n        Dense(4, activation='softmax')  # Output layer with 4 units (one for each class)\n    ])\n    return model\n\n# Create the CNN model using the defined function\nmodel = create_model()\n\n# Compile the model with Adam optimizer, categorical cross-entropy loss, and accuracy metric\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:21:11.417569Z","iopub.status.idle":"2024-12-26T21:21:11.417877Z","shell.execute_reply.started":"2024-12-26T21:21:11.417737Z","shell.execute_reply":"2024-12-26T21:21:11.417752Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train The Model","metadata":{}},{"cell_type":"code","source":"# Train the model using the training and validation data generators\nhistory = model.fit(\n    train_generator,  # Generator for training data\n    epochs=50,  # Number of epochs to train the model\n    validation_data=val_generator  # Generator for validation data\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:21:11.418934Z","iopub.status.idle":"2024-12-26T21:21:11.419269Z","shell.execute_reply.started":"2024-12-26T21:21:11.419091Z","shell.execute_reply":"2024-12-26T21:21:11.419105Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test the model","metadata":{}},{"cell_type":"code","source":"# Evaluate the model using the test data generator\ntest_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator))\n\n# Print the test loss and accuracy\nprint(f\"Test Loss: {test_loss}\")\nprint(f\"Test Accuracy: {test_accuracy}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:21:11.420985Z","iopub.status.idle":"2024-12-26T21:21:11.421705Z","shell.execute_reply.started":"2024-12-26T21:21:11.421469Z","shell.execute_reply":"2024-12-26T21:21:11.421493Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize training & validation accuracy and Loss Values","metadata":{}},{"cell_type":"code","source":"# Import the necessary library for plotting\nimport matplotlib.pyplot as plt\n\n# Create a figure with a specific size\nplt.figure(figsize=(12, 4))\n\n# Plot training and validation accuracy values\nplt.subplot(1, 2, 1)  # Create a subplot (1 row, 2 columns, 1st plot)\nplt.plot(history.history['accuracy'])  # Plot training accuracy\nplt.plot(history.history['val_accuracy'])  # Plot validation accuracy\nplt.title('Model Accuracy')  # Set the title of the plot\nplt.xlabel('Epoch')  # Set the x-axis label\nplt.ylabel('Accuracy')  # Set the y-axis label\nplt.legend(['Train', 'Validation'], loc='upper left')  # Add a legend to differentiate training and validation accuracy\n\n# Plot training and validation loss values\nplt.subplot(1, 2, 2)  # Create a subplot (1 row, 2 columns, 2nd plot)\nplt.plot(history.history['loss'])  # Plot training loss\nplt.plot(history.history['val_loss'])  # Plot validation loss\nplt.title('Model Loss')  # Set the title of the plot\nplt.xlabel('Epoch')  # Set the x-axis label\nplt.ylabel('Loss')  # Set the y-axis label\nplt.legend(['Train', 'Validation'], loc='upper left')  # Add a legend to differentiate training and validation loss\n\n# Adjust the layout to prevent overlap\nplt.tight_layout()\n\n# Display the plots\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:21:11.423025Z","iopub.status.idle":"2024-12-26T21:21:11.423384Z","shell.execute_reply.started":"2024-12-26T21:21:11.423188Z","shell.execute_reply":"2024-12-26T21:21:11.423203Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Some Examples","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:21:11.424388Z","iopub.status.idle":"2024-12-26T21:21:11.424987Z","shell.execute_reply.started":"2024-12-26T21:21:11.424856Z","shell.execute_reply":"2024-12-26T21:21:11.424871Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# try model in random image ","metadata":{}},{"cell_type":"code","source":"# Define the class labels dictionary\nclasses = {\n    0: \"Closed\",\n    1: \"Open\",\n    2: \"no_yawn\",\n    3: \"yawn\"\n}\n\n# Path to the image you want to predict\nimage_path = '/kaggle/input/drowsiness-dataset/train/Closed/_1.jpg'\n\n# Read the image using matplotlib\nimage = plt.imread(image_path)\n\n# Resize the image to (150,150) using OpenCV\nresized_image = cv2.resize(image, (150, 150))\n\n# Convert the image to grayscale\ngray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n\n# Add a channel dimension to the image\ngray_image = np.expand_dims(gray_image, axis=-1)\n\n# Add a batch dimension to the image\ngray_image = np.expand_dims(gray_image, axis=0)\n\n# Predict the class of the image\npredictions = model.predict(gray_image)\n\n# Convert predicted probabilities to class index\npredicted_class = np.argmax(predictions, axis=1)[0]\n\n# Retrieve the class label from the dictionary\npredicted_label = classes[predicted_class]\n\nprint(f\"Actual Class Closed\")\nprint(f\"Predicted Class: {predicted_label}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:21:11.426784Z","iopub.status.idle":"2024-12-26T21:21:11.427085Z","shell.execute_reply.started":"2024-12-26T21:21:11.426937Z","shell.execute_reply":"2024-12-26T21:21:11.426952Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# save model","metadata":{}},{"cell_type":"code","source":"import pickle\nimport tensorflow as tf\n\n# # Assuming 'model' is your trained TensorFlow model\n# model.save('DDD-model.pkl')\n\nmodel.save(\"DDD_model.h5\")\nprint(\"Model saved as DDD_model.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T21:21:11.428361Z","iopub.status.idle":"2024-12-26T21:21:11.428655Z","shell.execute_reply.started":"2024-12-26T21:21:11.428517Z","shell.execute_reply":"2024-12-26T21:21:11.428532Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# End","metadata":{}}]}